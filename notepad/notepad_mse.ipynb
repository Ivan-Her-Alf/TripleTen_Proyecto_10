{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0e9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Inspección inicial del dataset\n",
    "# Objetivo: Realizar un análisis exploratorio básico para\n",
    "# verificar estructura, calidad y consistencia de los datos\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def inspect_data(df):\n",
    "    # Mostrar las primeras filas para entender la estructura\n",
    "    print(\"Primeras filas del dataset:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Mostrar información general (número de registros, tipos de datos, memoria)\n",
    "    print(\"\\nInformación general del dataset:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    # Contar valores nulos por cada columna\n",
    "    print(\"\\nValores nulos por columna:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Contar registros duplicados\n",
    "    print(\"\\nValores duplicados en el dataset:\")\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    # Mostrar tipos de datos de cada columna\n",
    "    print(\"\\nTipos de datos por columna:\")\n",
    "    print(df.dtypes) \n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: División del dataset\n",
    "# Objetivo: Separar el dataset en entrenamiento (60%),\n",
    "# validación (20%) y prueba (20%)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def split_data(df, y_column, random_state=12345):\n",
    "    \n",
    "    # Separar variables independientes (X) y variable objetivo (y)\n",
    "    x = df.drop(y_column, axis=1)\n",
    "    y = df[y_column]\n",
    "    \n",
    "    # Primera división: 60% train, 40% temporal\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "        x, y, test_size=0.4, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Segunda división: dividir el 40% en 20% valid y 20% test\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(\n",
    "        x_temp, y_temp, test_size=0.5, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Retornar todos los subconjuntos\n",
    "    return x_train, x_valid, x_test, y_train, y_valid, y_test\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Regresión Logística con optimización de C\n",
    "# Objetivo: Encontrar el mejor hiperparámetro C que\n",
    "# maximice la exactitud en el conjunto de validación\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def logistic_model(features_train, target_train, features_valid, target_valid):\n",
    "    \n",
    "    best_model = None      # Guardará el mejor modelo encontrado\n",
    "    best_acc = 0           # Guardará la mejor exactitud\n",
    "    best_c = 0             # Guardará el mejor valor de C\n",
    "    \n",
    "    # Búsqueda manual de hiperparámetro C\n",
    "    for c in [0.01, 0.1, 1, 10, 100]:\n",
    "        \n",
    "        # Crear modelo con el valor actual de C\n",
    "        model = LogisticRegression(C=c, max_iter=1000, random_state=12345)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        # Predecir en validación\n",
    "        predictions = model.predict(features_valid)\n",
    "        \n",
    "        # Calcular exactitud\n",
    "        acc = accuracy_score(target_valid, predictions)\n",
    "        \n",
    "        # Guardar modelo si mejora la exactitud\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model = model\n",
    "            best_c = c\n",
    "    \n",
    "    return best_model, best_acc, best_c\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Árbol de Decisión con optimización de profundidad\n",
    "# Objetivo: Encontrar la mejor profundidad (max_depth)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def decision_tree_model(features_train, target_train, features_valid, target_valid):\n",
    "    \n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    best_depth = 0\n",
    "    \n",
    "    # Búsqueda del mejor max_depth\n",
    "    for depth in range(1, 21):\n",
    "        \n",
    "        model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        predictions = model.predict(features_valid)\n",
    "        acc = accuracy_score(target_valid, predictions)\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model = model\n",
    "            best_depth = depth\n",
    "    \n",
    "    return best_model, best_acc, best_depth\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Random Forest con optimización de hiperparámetros\n",
    "# Objetivo: Encontrar la mejor combinación de:\n",
    "# - n_estimators (número de árboles)\n",
    "# - max_depth (profundidad máxima)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def random_forest_model(features_train, target_train, features_valid, target_valid):\n",
    "    \n",
    "    best_model = None\n",
    "    best_acc = 0\n",
    "    best_depth = 0\n",
    "    best_est = 0\n",
    "    \n",
    "    # Búsqueda doble de hiperparámetros\n",
    "    for est in range(10, 101, 10):      # número de árboles\n",
    "        for depth in range(1, 21):      # profundidad máxima\n",
    "            \n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=est,\n",
    "                max_depth=depth,\n",
    "                random_state=12345\n",
    "            )\n",
    "            \n",
    "            model.fit(features_train, target_train)\n",
    "            \n",
    "            predictions = model.predict(features_valid)\n",
    "            acc = accuracy_score(target_valid, predictions)\n",
    "            \n",
    "            # Guardar mejor combinación encontrada\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = model\n",
    "                best_depth = depth\n",
    "                best_est = est\n",
    "    \n",
    "    return best_model, best_acc, best_depth, best_est\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Comparación de modelos\n",
    "# Objetivo: Comparar los mejores modelos encontrados\n",
    "# y seleccionar el que tenga mayor exactitud\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def compare_models(log_model, tree_model, rf_model,\n",
    "                   log_acc, tree_acc, rf_acc):\n",
    "    \n",
    "    # Diccionario con nombre del modelo y su desempeño\n",
    "    results = {\n",
    "        \"Logistic Regression\": (log_model, log_acc),\n",
    "        \"Decision Tree\": (tree_model, tree_acc),\n",
    "        \"Random Forest\": (rf_model, rf_acc)\n",
    "    }\n",
    "    \n",
    "    # Seleccionar el modelo con mayor exactitud\n",
    "    best_name = max(results, key=lambda x: results[x][1])\n",
    "    \n",
    "    best_model = results[best_name][0]\n",
    "    best_acc = results[best_name][1]\n",
    "    \n",
    "    return best_name, best_model, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcda551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Sanity Check del Dataset\n",
    "# Objetivo: Realizar una verificación rápida para asegurar\n",
    "# que los datos tienen sentido antes de entrenar modelos.\n",
    "# Incluye:\n",
    "# - Dimensiones del dataset\n",
    "# - Distribución de la variable objetivo\n",
    "# - Estadísticas descriptivas de las variables numéricas\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def sanity_check_data(df, target_column):\n",
    "    \n",
    "    # Mostrar número de filas y columnas\n",
    "    print(\"Dimensiones:\", df.shape)\n",
    "    \n",
    "    # Mostrar proporción de cada clase (normalizada)\n",
    "    # Permite verificar si el dataset está balanceado o desbalanceado\n",
    "    print(\"\\nDistribución del target:\")\n",
    "    print(df[target_column].value_counts(normalize=True))\n",
    "    \n",
    "    # Mostrar estadísticas descriptivas:\n",
    "    # media, desviación estándar, mínimo, máximo, etc.\n",
    "    # Útil para detectar valores atípicos o inconsistencias\n",
    "    print(\"\\nEstadísticas descriptivas:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "# ---------------------------------------------------------\n",
    "# FUNCIÓN: Sanity Check del Modelo (Baseline)\n",
    "# Objetivo: Crear un modelo base que siempre prediga la\n",
    "# clase mayoritaria. Esto sirve como punto de comparación.\n",
    "# Si el modelo entrenado no supera este baseline,\n",
    "# entonces no está aprendiendo correctamente.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def sanity_check_model(target):\n",
    "    \n",
    "    # Obtener la clase más frecuente en el conjunto de datos\n",
    "    majority_class = target.mode()[0]\n",
    "    \n",
    "    # Crear predicciones constantes (todas iguales a la clase mayoritaria)\n",
    "    baseline_predictions = [majority_class] * len(target)\n",
    "    \n",
    "    # Calcular exactitud del baseline\n",
    "    baseline_accuracy = accuracy_score(target, baseline_predictions)\n",
    "    \n",
    "    # Mostrar resultado\n",
    "    print(\"Accuracy baseline:\", baseline_accuracy)\n",
    "    \n",
    "    # Retornar exactitud para compararla con modelos entrenados\n",
    "    return baseline_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c0ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_csv(r'C:\\Users\\ACER\\Documents\\Proyectos TripleTen\\TripleTen_Proyecto_10\\files\\users_behavior.csv')\n",
    "df['is_ultra'] = df['is_ultra'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae6bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Información general del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n",
      "\n",
      "Valores nulos por columna:\n",
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "\n",
      "Valores duplicados en el dataset:\n",
      "0\n",
      "\n",
      "Tipos de datos por columna:\n",
      "calls       float64\n",
      "minutes     float64\n",
      "messages    float64\n",
      "mb_used     float64\n",
      "is_ultra      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspeccion inicial de df\n",
    "inspect_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2270fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division de df\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = split_data(df,'is_ultra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e22031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrida de modelos\n",
    "log_model, log_acc, log_c = logistic_model(x_train, y_train, x_valid, y_valid)\n",
    "tree_model, tree_acc, tree_depth = decision_tree_model(x_train, y_train, x_valid, y_valid)\n",
    "rf_model, rf_acc, rf_depth, rf_est = random_forest_model(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b61b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_model: LogisticRegression(C=0.01, max_iter=1000, random_state=12345)\n",
      "tree_model: DecisionTreeClassifier(max_depth=3, random_state=12345)\n",
      "rf_model: RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# Comparación de modelos\n",
    "print(f'log_model: {log_model}')\n",
    "print(f'tree_model: {tree_model}')\n",
    "print(f'rf_model: {rf_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acaf961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobracion de modelos\n",
    "best_name, best_model, best_valid_acc = compare_models(log_model, tree_model, rf_model, log_acc, tree_acc, rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a83405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: Random Forest\n",
      "Accuracy validación: 0.8087091757387247\n",
      "Accuracy test: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "# Evaluar modelos en test\n",
    "test_predictions = best_model.predict(x_test)\n",
    "test_acc = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(\"Mejor modelo:\", best_name)\n",
    "print(\"Accuracy validación:\", best_valid_acc)\n",
    "print(\"Accuracy test:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3787a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones: (3214, 5)\n",
      "\n",
      "Distribución del target:\n",
      "is_ultra\n",
      "0    0.693528\n",
      "1    0.306472\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n",
      "\n",
      "Accuracy baseline: 0.6924273858921162\n",
      "\n",
      "Modelo cumple con sanity check: True\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check\n",
    "sanity_check_data(df,'is_ultra')\n",
    "print()\n",
    "baseline_acc = sanity_check_model(y_train)\n",
    "print('\\nModelo cumple con sanity check:',baseline_acc < best_valid_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
